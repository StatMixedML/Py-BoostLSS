{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22aca876-6dee-4cd3-a528-d2561a7ad301",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <center> <h1> <font size=\"8\"> Multivariate Gaussian Example </font> </h1> </center>\n",
    "    <center> <h1> <font size=\"5\"> Cholesky Decomposition of Covariance Matrix $\\Sigma$  </font> </h1> </center>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdebff11-9988-4b5b-a2ad-3684afd3d2c0",
   "metadata": {},
   "source": [
    "In this example, we model and predict all parameters of a trivariate ($Y_{D}=3$) Normal distribution. The conditional means $\\mathbf{\\mu}(x) \\in \\mathbb{R}^{D}$ and the conditional covariance matrix $\\mathbf{\\Sigma}(x) \\in \\mathbb{R}^{D \\times D}$ are given as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247dc33d-ac22-4e51-b500-d4b61fae21bf",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{\\mu}(x)=\\begin{pmatrix}\\mu_{1}(x) \\\\ \\mu_{2}(x) \\\\ \\mu_{3}(x)\\end{pmatrix}, \\qquad \\qquad  \n",
    "\\mathbf{\\Sigma}(x)= \\begin{pmatrix}\n",
    "\\sigma^{2}_{11}(x) & \\rho_{1,2}(x)\\sigma_{1}(x)\\sigma_{2}(x) & \\rho_{1,3}(x)\\sigma_{1}(x)\\sigma_{3}(x) \\\\\n",
    "\\rho_{2,1}(x)\\sigma_{2}(x)\\sigma_{1}(x) & \\sigma^{2}_{22}(x) & \\rho_{2,3}(x)\\sigma_{2}(x)\\sigma_{3}(x) \\\\\n",
    "\\rho_{3,1}(x)\\sigma_{3}(x)\\sigma_{1}(x) & \\rho_{3,2}(x)\\sigma_{3}(x)\\sigma_{2}(x) &  \\sigma^{2}_{33}(x)\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a31887-1f1a-4b79-9931-18130ef6f2f3",
   "metadata": {},
   "source": [
    "To ensure positive definiteness of $\\Sigma(\\cdot)$, the $D(D + 1)/2$ entries of the covariance matrix must satisfy specific conditions. For the bivariate case, this can be ensured by applying exponential functions to the variances and a suitable transformation to restrict the coefficient of correlation $\\rho \\in [−1,1]$. However, in high-dimensional settings, where all moments are modelled as functions of covariates, ensuring positive definiteness of the covariance matrix becomes challenging, since joint restrictions for the elements are necessary. A computationally more tractable approach to ensure positive definiteness is based on the Cholesky decomposition, that uniquely decomposes the covariance matrix as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1dd3b-963e-4c60-8732-60fe93a300d7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{\\Sigma}(x) = \\mathbf{L}(x) \\mathbf{L}^{\\prime}(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042fa61-9b9a-4aa0-aaab-5cf05298fdad",
   "metadata": {},
   "source": [
    "where $\\mathbf{L}(\\cdot) \\in \\mathbb{R}^{D \\times D}$ is a lower triangular matrix. To ensure $\\mathbf{\\Sigma}(\\cdot)$ to be positive definite, the $D$ diagonal elements $\\ell_{ii}$ of\n",
    "$\\mathbf{L}(\\cdot)$ need to be strictly positive, whereas all $D(D −1)/2$ off diagonal elements $\\ell_{ij}$ can take on any value. For the trivariate case, the Cholesky factor $\\mathbf{L}(\\cdot)$ is given as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d899c51-8c96-4583-9ea4-86674196ba6e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{L}(x)= \\begin{pmatrix}\n",
    "\\exp\\big(\\ell_{11}(x)\\big) & 0 & 0 \\\\\n",
    "\\ell_{21} & \\exp\\big(\\ell_{22}(x)\\big) & 0 \\\\\n",
    "\\ell_{31} & \\ell_{32} & \\exp\\big(\\ell_{33}(x)\\big)\\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86229dd0-bccf-41a1-800f-18892f451a21",
   "metadata": {},
   "source": [
    "Given the usefulness of the Cholesky decomposition, instead of estimating the entries of $\\mathbf{\\Sigma}(\\cdot)$ directly, Py-BoostLSS estimates the Cholesky factors $\\mathbf{L}(\\cdot)$ and then uses these for creating $\\mathbf{\\Sigma}(\\cdot)$. However, in contrast to the original formulation of $\\mathbf{\\Sigma}(\\cdot)$, the elements in $\\mathbf{L}(\\cdot)$ do not have any direct interpretation. For more details, we refer to our related paper **[März, Alexander (2022), *Multi-Target XGBoostLSS Regression*](https://arxiv.org/abs/2210.06831)**.\n",
    "\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b4eea0-96b6-482a-afc9-7ec867bf2193",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de768b2-ef44-434d-89e4-402170de0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from pyboostlss.model import *\n",
    "from pyboostlss.distributions.MVN import *\n",
    "from pyboostlss.distributions.distribution_loss_metric import *\n",
    "from pyboostlss.utils import *\n",
    "from pyboostlss.datasets.data_loader import load_simulated_data\n",
    "\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "plotnine.options.figure_size = (20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e90e9e4-5902-4299-9236-d31af4e29b2b",
   "metadata": {},
   "source": [
    "# Specifiy Distribtution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75224245-9b11-4730-a4c6-d7fe6b3a272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = MVN(D=3) # Multivariate Normal, where D specifies the number of target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c36cd5-11f4-4c03-8297-c2555924bd4a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78118dfc-6b05-4634-ae15-9fbf3d30b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sim = load_simulated_data(\"sim_triv_gaussian.csv\")\n",
    "\n",
    "# Create 60%, 20%, 20% split for train, validation and test \n",
    "train, validate, test = np.split(data_sim.sample(frac=1,random_state=123), [int(0.6*len(data_sim)), int(0.8*len(data_sim))])\n",
    "\n",
    "# Train\n",
    "x_train = train[\"x\"].values.reshape(-1,1)\n",
    "y_train = train.filter(regex=\"y\").values\n",
    "dtrain = {\"X\": x_train, \"y\": y_train}\n",
    "\n",
    "# Validation\n",
    "x_eval = validate[\"x\"].values.reshape(-1,1)\n",
    "y_eval = validate.filter(regex=\"y\").values\n",
    "eval_sets = [{'X': x_eval, 'y': y_eval}] # Specifies eval_sets on which the model is evaluated on\n",
    "\n",
    "# Test\n",
    "x_test = test[\"x\"].values.reshape(-1,1)\n",
    "y_test = test.filter(regex=\"y\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742234a-ad21-4a32-aa80-08c59d318503",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Optimization via Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8403d-ea56-4d44-ba26-1f86632b7b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-05 14:43:12,363]\u001b[0m A new study created in memory with name: Py-BoostLSS Hyper-Parameter Optimization\u001b[0m\n",
      "C:\\Users\\Alexander\\.julia\\v0.6\\Conda\\deps\\usr\\envs\\pyboost\\lib\\site-packages\\optuna\\progress_bar.py:49: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e69332aee94878a2095c24cec10a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:43:21] Stdout logging level is INFO.\n",
      "[14:43:21] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:43:25] Iter 0; Sample 0, NLL-score = 9159.097514649005; \n",
      "[14:43:42] Early stopping at iter 283, best iter 263, best_score 7044.187375765239\n",
      "\u001b[32m[I 2022-12-05 14:43:42,468]\u001b[0m Trial 0 finished with value: 7044.1875 and parameters: {'lr': 0.1558435081316784, 'max_depth': 2, 'sketch_outputs': 3, 'lambda_l2': 35.11016881402264, 'colsample': 0.7833804357866407, 'subsample': 0.8842605465240376, 'min_gain_to_split': 53.196536295253836}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:43:42] Stdout logging level is INFO.\n",
      "[14:43:42] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:43:42] Iter 0; Sample 0, NLL-score = 8481.327933285344; \n",
      "[14:43:45] Early stopping at iter 49, best iter 29, best_score 7104.789121997672\n",
      "\u001b[32m[I 2022-12-05 14:43:46,051]\u001b[0m Trial 1 finished with value: 7104.7890625 and parameters: {'lr': 0.44510304831717556, 'max_depth': 4, 'sketch_outputs': 8, 'lambda_l2': 38.22762081078068, 'colsample': 0.5446190732871548, 'subsample': 0.47323320309145267, 'min_gain_to_split': 307.0977547426909}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:43:46] Stdout logging level is INFO.\n",
      "[14:43:46] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:43:46] Iter 0; Sample 0, NLL-score = 9062.123347933488; \n",
      "[14:43:50] Early stopping at iter 77, best iter 57, best_score 7107.2896162423\n",
      "\u001b[32m[I 2022-12-05 14:43:50,965]\u001b[0m Trial 2 finished with value: 7107.2900390625 and parameters: {'lr': 0.4280748111811929, 'max_depth': 2, 'sketch_outputs': 9, 'lambda_l2': 24.016894148009442, 'colsample': 0.6866217950196924, 'subsample': 0.3150233295064575, 'min_gain_to_split': 194.22035575533835}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:43:50] Stdout logging level is INFO.\n",
      "[14:43:50] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:43:51] Iter 0; Sample 0, NLL-score = 8782.3557414122; \n",
      "[14:43:59] Early stopping at iter 132, best iter 112, best_score 7217.33920453925\n",
      "\u001b[32m[I 2022-12-05 14:43:59,362]\u001b[0m Trial 3 finished with value: 7217.3388671875 and parameters: {'lr': 0.8176653604721728, 'max_depth': 2, 'sketch_outputs': 2, 'lambda_l2': 17.113320705314358, 'colsample': 0.4436591160881507, 'subsample': 0.49990014474507527, 'min_gain_to_split': 490.7306790600032}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:43:59] Stdout logging level is INFO.\n",
      "[14:43:59] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:43:59] Iter 0; Sample 0, NLL-score = 9158.973279935764; \n",
      "[14:44:06] Early stopping at iter 117, best iter 97, best_score 7051.3430453453875\n",
      "\u001b[32m[I 2022-12-05 14:44:07,112]\u001b[0m Trial 4 finished with value: 7051.34326171875 and parameters: {'lr': 0.17579488002612195, 'max_depth': 3, 'sketch_outputs': 9, 'lambda_l2': 29.098570487051774, 'colsample': 0.5484869316095171, 'subsample': 0.9881471856948698, 'min_gain_to_split': 424.77305752558937}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:44:07] Stdout logging level is INFO.\n",
      "[14:44:07] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:44:07] Iter 0; Sample 0, NLL-score = 8673.13744602327; \n",
      "[14:44:10] Early stopping at iter 43, best iter 23, best_score 7295.323183142447\n",
      "\u001b[32m[I 2022-12-05 14:44:10,076]\u001b[0m Trial 5 finished with value: 7295.3232421875 and parameters: {'lr': 0.8385191429719995, 'max_depth': 3, 'sketch_outputs': 7, 'lambda_l2': 37.89223449811428, 'colsample': 0.8913819976779227, 'subsample': 0.3168142611032585, 'min_gain_to_split': 346.18411721042827}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:44:10] Stdout logging level is INFO.\n",
      "[14:44:10] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:44:10] Iter 0; Sample 0, NLL-score = 8725.48615690309; \n",
      "[14:44:18] Early stopping at iter 125, best iter 105, best_score 7151.317155221874\n",
      "\u001b[32m[I 2022-12-05 14:44:18,389]\u001b[0m Trial 6 finished with value: 7151.3173828125 and parameters: {'lr': 0.8722589609492379, 'max_depth': 2, 'sketch_outputs': 8, 'lambda_l2': 24.48079078364128, 'colsample': 0.2447203957324341, 'subsample': 0.6285304710238441, 'min_gain_to_split': 498.4010438764548}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:44:18] Stdout logging level is INFO.\n",
      "[14:44:18] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:44:18] Iter 0; Sample 0, NLL-score = 8814.490841066741; \n",
      "[14:44:22] Early stopping at iter 48, best iter 28, best_score 7076.079852974157\n",
      "\u001b[32m[I 2022-12-05 14:44:22,737]\u001b[0m Trial 7 finished with value: 7076.080078125 and parameters: {'lr': 0.24183624746728624, 'max_depth': 4, 'sketch_outputs': 6, 'lambda_l2': 2.5735213119332334, 'colsample': 0.26171030004957513, 'subsample': 0.7761513033958412, 'min_gain_to_split': 112.57084640597998}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:44:22] Stdout logging level is INFO.\n",
      "[14:44:22] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:44:22] Iter 0; Sample 0, NLL-score = 8685.311855415846; \n",
      "[14:44:28] Early stopping at iter 76, best iter 56, best_score 7085.938937766767\n",
      "\u001b[32m[I 2022-12-05 14:44:28,448]\u001b[0m Trial 8 finished with value: 7085.93896484375 and parameters: {'lr': 0.3017479308634768, 'max_depth': 3, 'sketch_outputs': 5, 'lambda_l2': 7.938778789201737, 'colsample': 0.52093359539986, 'subsample': 0.594993951061167, 'min_gain_to_split': 100.67819713250498}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:44:28] Stdout logging level is INFO.\n",
      "[14:44:28] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:44:28] Iter 0; Sample 0, NLL-score = 8532.981660570305; \n",
      "[14:44:32] Early stopping at iter 62, best iter 42, best_score 7087.310922406313\n",
      "\u001b[32m[I 2022-12-05 14:44:32,836]\u001b[0m Trial 9 finished with value: 7087.31103515625 and parameters: {'lr': 0.7273017811983369, 'max_depth': 3, 'sketch_outputs': 4, 'lambda_l2': 34.92741680053434, 'colsample': 0.3252494582380312, 'subsample': 0.9683255862486357, 'min_gain_to_split': 17.5802213590745}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:44:32] Stdout logging level is INFO.\n",
      "[14:44:32] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:44:32] Iter 0; Sample 0, NLL-score = 9283.454466112637; \n",
      "[14:45:03] Iter 499; Sample 0, NLL-score = 8678.787061988856; \n",
      "\u001b[32m[I 2022-12-05 14:45:04,210]\u001b[0m Trial 10 finished with value: 8678.787109375 and parameters: {'lr': 0.0029552125633407755, 'max_depth': 1, 'sketch_outputs': 1, 'lambda_l2': 13.745781943851437, 'colsample': 0.9630429345655973, 'subsample': 0.7916624108920056, 'min_gain_to_split': 23.555976676677574}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:45:04] Stdout logging level is INFO.\n",
      "[14:45:04] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:45:04] Iter 0; Sample 0, NLL-score = 9271.171708698486; \n",
      "[14:45:33] Iter 499; Sample 0, NLL-score = 7802.349384940133; \n",
      "\u001b[32m[I 2022-12-05 14:45:34,131]\u001b[0m Trial 11 finished with value: 7802.349609375 and parameters: {'lr': 0.016159994422070945, 'max_depth': 1, 'sketch_outputs': 10, 'lambda_l2': 29.859077034304196, 'colsample': 0.7480563866066177, 'subsample': 0.9950341361193098, 'min_gain_to_split': 387.07455819836946}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:45:34] Stdout logging level is INFO.\n",
      "[14:45:34] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:45:34] Iter 0; Sample 0, NLL-score = 9136.386560918945; \n",
      "[14:45:47] Early stopping at iter 196, best iter 176, best_score 7076.047414813731\n",
      "\u001b[32m[I 2022-12-05 14:45:47,897]\u001b[0m Trial 12 finished with value: 7076.0478515625 and parameters: {'lr': 0.18760956243752208, 'max_depth': 2, 'sketch_outputs': 3, 'lambda_l2': 30.330799558084863, 'colsample': 0.7788410874717192, 'subsample': 0.8468746749521247, 'min_gain_to_split': 250.23773434277825}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:45:47] Stdout logging level is INFO.\n",
      "[14:45:47] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:45:48] Iter 0; Sample 0, NLL-score = 8537.73573165928; \n",
      "[14:45:53] Early stopping at iter 75, best iter 55, best_score 7111.881086574427\n",
      "\u001b[32m[I 2022-12-05 14:45:53,492]\u001b[0m Trial 13 finished with value: 7111.880859375 and parameters: {'lr': 0.6329456191484018, 'max_depth': 3, 'sketch_outputs': 4, 'lambda_l2': 31.18482141302923, 'colsample': 0.6450605971431023, 'subsample': 0.8878850939894095, 'min_gain_to_split': 420.8189364183187}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:45:53] Stdout logging level is INFO.\n",
      "[14:45:53] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:45:53] Iter 0; Sample 0, NLL-score = 9205.209305173037; \n",
      "[14:46:25] Iter 499; Sample 0, NLL-score = 7072.815850335445; \n",
      "\u001b[32m[I 2022-12-05 14:46:25,989]\u001b[0m Trial 14 finished with value: 7072.0361328125 and parameters: {'lr': 0.15537420589453088, 'max_depth': 1, 'sketch_outputs': 6, 'lambda_l2': 24.332338598766682, 'colsample': 0.8155946061829582, 'subsample': 0.7047914478537517, 'min_gain_to_split': 169.80562097598124}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:46:26] Stdout logging level is INFO.\n",
      "[14:46:26] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:46:26] Iter 0; Sample 0, NLL-score = 9220.116964683193; \n",
      "[14:46:34] Early stopping at iter 118, best iter 98, best_score 7069.277490138728\n",
      "\u001b[32m[I 2022-12-05 14:46:34,260]\u001b[0m Trial 15 finished with value: 7069.2783203125 and parameters: {'lr': 0.3298350050677249, 'max_depth': 4, 'sketch_outputs': 1, 'lambda_l2': 33.70577924663483, 'colsample': 0.6026159195511133, 'subsample': 0.9207472031925118, 'min_gain_to_split': 273.42479105688386}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:46:34] Stdout logging level is INFO.\n",
      "[14:46:34] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:46:34] Iter 0; Sample 0, NLL-score = 8660.918425286653; \n",
      "[14:46:36] Early stopping at iter 31, best iter 11, best_score 7263.44390725499\n",
      "\u001b[32m[I 2022-12-05 14:46:36,557]\u001b[0m Trial 16 finished with value: 7263.4443359375 and parameters: {'lr': 0.592798445859859, 'max_depth': 3, 'sketch_outputs': 10, 'lambda_l2': 27.17583235825233, 'colsample': 0.4146336293420169, 'subsample': 0.2053559062371062, 'min_gain_to_split': 164.93799801328754}. Best is trial 0 with value: 7044.1875.\u001b[0m\n",
      "[14:46:36] Stdout logging level is INFO.\n",
      "[14:46:36] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:46:36] Iter 0; Sample 0, NLL-score = 9187.864711500833; \n",
      "[14:46:59] Early stopping at iter 347, best iter 327, best_score 7041.895649521588\n",
      "\u001b[32m[I 2022-12-05 14:47:00,232]\u001b[0m Trial 17 finished with value: 7041.89599609375 and parameters: {'lr': 0.11905667303902112, 'max_depth': 2, 'sketch_outputs': 3, 'lambda_l2': 39.628795062527686, 'colsample': 0.8744973848774316, 'subsample': 0.8263905019123107, 'min_gain_to_split': 423.87083609206684}. Best is trial 17 with value: 7041.89599609375.\u001b[0m\n",
      "[14:47:00] Stdout logging level is INFO.\n",
      "[14:47:00] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:47:00] Iter 0; Sample 0, NLL-score = 9213.779505123975; \n",
      "[14:47:24] Early stopping at iter 347, best iter 327, best_score 7040.356340598177\n",
      "\u001b[32m[I 2022-12-05 14:47:25,531]\u001b[0m Trial 18 finished with value: 7040.3564453125 and parameters: {'lr': 0.0860139003894272, 'max_depth': 2, 'sketch_outputs': 3, 'lambda_l2': 39.92878188427043, 'colsample': 0.9839797324898852, 'subsample': 0.7730746455426359, 'min_gain_to_split': 72.61768764139177}. Best is trial 18 with value: 7040.3564453125.\u001b[0m\n",
      "[14:47:25] Stdout logging level is INFO.\n",
      "[14:47:25] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:47:25] Iter 0; Sample 0, NLL-score = 8929.945067898312; \n",
      "[14:47:38] Early stopping at iter 203, best iter 183, best_score 7197.8281456775685\n",
      "\u001b[32m[I 2022-12-05 14:47:38,915]\u001b[0m Trial 19 finished with value: 7197.828125 and parameters: {'lr': 0.9721433664136877, 'max_depth': 1, 'sketch_outputs': 3, 'lambda_l2': 39.131771529015346, 'colsample': 0.9866769196197085, 'subsample': 0.717842047365305, 'min_gain_to_split': 208.2482244027869}. Best is trial 18 with value: 7040.3564453125.\u001b[0m\n",
      "[14:47:38] Stdout logging level is INFO.\n",
      "[14:47:38] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:47:39] Iter 0; Sample 0, NLL-score = 9183.795686841335; \n",
      "[14:48:09] Early stopping at iter 449, best iter 429, best_score 7048.259744959551\n",
      "\u001b[32m[I 2022-12-05 14:48:10,055]\u001b[0m Trial 20 finished with value: 7048.26025390625 and parameters: {'lr': 0.07833988200667917, 'max_depth': 2, 'sketch_outputs': 2, 'lambda_l2': 18.227881315813885, 'colsample': 0.8881602254835668, 'subsample': 0.635134322422773, 'min_gain_to_split': 325.69098189527705}. Best is trial 18 with value: 7040.3564453125.\u001b[0m\n",
      "[14:48:10] Stdout logging level is INFO.\n",
      "[14:48:10] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:48:10] Iter 0; Sample 0, NLL-score = 9138.683680130078; \n",
      "[14:48:36] Early stopping at iter 348, best iter 328, best_score 7033.19637345779\n",
      "\u001b[32m[I 2022-12-05 14:48:36,584]\u001b[0m Trial 21 finished with value: 7033.19677734375 and parameters: {'lr': 0.12247022876994895, 'max_depth': 2, 'sketch_outputs': 4, 'lambda_l2': 34.699827335624235, 'colsample': 0.8765532961046525, 'subsample': 0.824561471787586, 'min_gain_to_split': 71.7464206933516}. Best is trial 21 with value: 7033.19677734375.\u001b[0m\n",
      "[14:48:36] Stdout logging level is INFO.\n",
      "[14:48:36] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:48:36] Iter 0; Sample 0, NLL-score = 9188.72940713256; \n",
      "[14:49:05] Early stopping at iter 408, best iter 388, best_score 7033.198644778351\n",
      "\u001b[32m[I 2022-12-05 14:49:05,936]\u001b[0m Trial 22 finished with value: 7033.19921875 and parameters: {'lr': 0.07796896975852372, 'max_depth': 2, 'sketch_outputs': 4, 'lambda_l2': 39.12197853264668, 'colsample': 0.8897814615518886, 'subsample': 0.8207105333689104, 'min_gain_to_split': 95.26056243111907}. Best is trial 21 with value: 7033.19677734375.\u001b[0m\n",
      "[14:49:05] Stdout logging level is INFO.\n",
      "[14:49:05] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:49:06] Iter 0; Sample 0, NLL-score = 8836.03106412643; \n",
      "[14:49:18] Early stopping at iter 177, best iter 157, best_score 7055.594948957098\n",
      "\u001b[32m[I 2022-12-05 14:49:18,222]\u001b[0m Trial 23 finished with value: 7055.5947265625 and parameters: {'lr': 0.32373686031284843, 'max_depth': 2, 'sketch_outputs': 5, 'lambda_l2': 34.58489901314707, 'colsample': 0.9448129389647688, 'subsample': 0.7270968653267033, 'min_gain_to_split': 92.36429571367655}. Best is trial 21 with value: 7033.19677734375.\u001b[0m\n",
      "[14:49:18] Stdout logging level is INFO.\n",
      "[14:49:18] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:49:18] Iter 0; Sample 0, NLL-score = 9244.13121408621; \n",
      "[14:49:50] Iter 499; Sample 0, NLL-score = 7212.476520162219; \n",
      "\u001b[32m[I 2022-12-05 14:49:51,684]\u001b[0m Trial 24 finished with value: 7212.4765625 and parameters: {'lr': 0.07077042010991282, 'max_depth': 1, 'sketch_outputs': 4, 'lambda_l2': 39.88193486819796, 'colsample': 0.8427899452027982, 'subsample': 0.7634275591440629, 'min_gain_to_split': 140.43538399277423}. Best is trial 21 with value: 7033.19677734375.\u001b[0m\n",
      "[14:49:51] Stdout logging level is INFO.\n",
      "[14:49:51] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:49:51] Iter 0; Sample 0, NLL-score = 8934.688698811513; \n",
      "[14:50:04] Early stopping at iter 167, best iter 147, best_score 7059.136540016086\n",
      "\u001b[32m[I 2022-12-05 14:50:04,528]\u001b[0m Trial 25 finished with value: 7059.13671875 and parameters: {'lr': 0.22990480645757855, 'max_depth': 2, 'sketch_outputs': 5, 'lambda_l2': 32.95873523875186, 'colsample': 0.9966168206208934, 'subsample': 0.6839365296158955, 'min_gain_to_split': 69.52198891299957}. Best is trial 21 with value: 7033.19677734375.\u001b[0m\n",
      "[14:50:04] Stdout logging level is INFO.\n",
      "[14:50:04] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:50:04] Iter 0; Sample 0, NLL-score = 8908.905202489723; \n",
      "[14:50:16] Early stopping at iter 169, best iter 149, best_score 7073.270981456897\n",
      "\u001b[32m[I 2022-12-05 14:50:16,640]\u001b[0m Trial 26 finished with value: 7073.271484375 and parameters: {'lr': 0.39445990238730777, 'max_depth': 2, 'sketch_outputs': 2, 'lambda_l2': 36.65228426171831, 'colsample': 0.9220580469512807, 'subsample': 0.5751734317946173, 'min_gain_to_split': 50.103689005717484}. Best is trial 21 with value: 7033.19677734375.\u001b[0m\n",
      "[14:50:16] Stdout logging level is INFO.\n",
      "[14:50:16] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:50:16] Iter 0; Sample 0, NLL-score = 9117.654434961067; \n",
      "[14:50:43] Early stopping at iter 403, best iter 383, best_score 7067.985873462437\n",
      "\u001b[32m[I 2022-12-05 14:50:44,387]\u001b[0m Trial 27 finished with value: 7067.986328125 and parameters: {'lr': 0.5292669656509812, 'max_depth': 1, 'sketch_outputs': 4, 'lambda_l2': 26.914986071293306, 'colsample': 0.7265749956185159, 'subsample': 0.8412094729708302, 'min_gain_to_split': 124.68079574444221}. Best is trial 21 with value: 7033.19677734375.\u001b[0m\n",
      "[14:50:44] Stdout logging level is INFO.\n",
      "[14:50:44] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:50:44] Iter 0; Sample 0, NLL-score = 9183.37317576815; \n",
      "[14:51:19] Iter 499; Sample 0, NLL-score = 7032.781506069121; \n",
      "\u001b[32m[I 2022-12-05 14:51:19,774]\u001b[0m Trial 28 finished with value: 7032.7314453125 and parameters: {'lr': 0.05278231702794737, 'max_depth': 2, 'sketch_outputs': 5, 'lambda_l2': 21.01984505271928, 'colsample': 0.8370972541372667, 'subsample': 0.8957241498925246, 'min_gain_to_split': 3.0950950454080726}. Best is trial 28 with value: 7032.7314453125.\u001b[0m\n",
      "[14:51:19] Stdout logging level is INFO.\n",
      "[14:51:19] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:51:19] Iter 0; Sample 0, NLL-score = 9101.617812109263; \n",
      "[14:51:27] Early stopping at iter 103, best iter 83, best_score 7055.376266505711\n",
      "\u001b[32m[I 2022-12-05 14:51:27,529]\u001b[0m Trial 29 finished with value: 7055.37646484375 and parameters: {'lr': 0.25377705660190986, 'max_depth': 3, 'sketch_outputs': 6, 'lambda_l2': 11.441535198930794, 'colsample': 0.8139789028201043, 'subsample': 0.878668495848923, 'min_gain_to_split': 13.385085709591209}. Best is trial 28 with value: 7032.7314453125.\u001b[0m\n",
      "[14:51:27] Stdout logging level is INFO.\n",
      "[14:51:27] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:51:27] Iter 0; Sample 0, NLL-score = 9281.638944230697; \n",
      "[14:51:58] Iter 499; Sample 0, NLL-score = 8631.275270699723; \n",
      "\u001b[32m[I 2022-12-05 14:51:58,877]\u001b[0m Trial 30 finished with value: 8631.275390625 and parameters: {'lr': 0.003198554188197894, 'max_depth': 1, 'sketch_outputs': 7, 'lambda_l2': 20.78707496825379, 'colsample': 0.6763118026564972, 'subsample': 0.9062419176072553, 'min_gain_to_split': 41.95236399419334}. Best is trial 28 with value: 7032.7314453125.\u001b[0m\n",
      "[14:51:58] Stdout logging level is INFO.\n",
      "[14:51:58] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:51:59] Iter 0; Sample 0, NLL-score = 9165.822807459193; \n",
      "[14:52:25] Early stopping at iter 419, best iter 399, best_score 7030.708794397505\n",
      "\u001b[32m[I 2022-12-05 14:52:25,730]\u001b[0m Trial 31 finished with value: 7030.70849609375 and parameters: {'lr': 0.09799072287189783, 'max_depth': 2, 'sketch_outputs': 4, 'lambda_l2': 36.28446929513354, 'colsample': 0.9075692260178042, 'subsample': 0.803103800757986, 'min_gain_to_split': 77.82782514554388}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:52:25] Stdout logging level is INFO.\n",
      "[14:52:25] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:52:25] Iter 0; Sample 0, NLL-score = 9073.352787746084; \n",
      "[14:52:43] Early stopping at iter 272, best iter 252, best_score 7042.6147254295665\n",
      "\u001b[32m[I 2022-12-05 14:52:44,062]\u001b[0m Trial 32 finished with value: 7042.615234375 and parameters: {'lr': 0.12399762804735605, 'max_depth': 2, 'sketch_outputs': 5, 'lambda_l2': 36.1596744833105, 'colsample': 0.8502810782272725, 'subsample': 0.9416167158768409, 'min_gain_to_split': 1.2034620999129118}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:52:44] Stdout logging level is INFO.\n",
      "[14:52:44] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:52:44] Iter 0; Sample 0, NLL-score = 9218.976599088535; \n",
      "[14:53:18] Iter 499; Sample 0, NLL-score = 7034.131783565515; \n",
      "\u001b[32m[I 2022-12-05 14:53:18,722]\u001b[0m Trial 33 finished with value: 7033.7548828125 and parameters: {'lr': 0.05149428062536879, 'max_depth': 2, 'sketch_outputs': 4, 'lambda_l2': 32.09500862393301, 'colsample': 0.9198004034303436, 'subsample': 0.8240966720946797, 'min_gain_to_split': 73.59795976362234}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:53:18] Stdout logging level is INFO.\n",
      "[14:53:18] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:53:18] Iter 0; Sample 0, NLL-score = 8994.720337710867; \n",
      "[14:53:33] Early stopping at iter 202, best iter 182, best_score 7054.295085394385\n",
      "\u001b[32m[I 2022-12-05 14:53:34,008]\u001b[0m Trial 34 finished with value: 7054.294921875 and parameters: {'lr': 0.17179693723244419, 'max_depth': 2, 'sketch_outputs': 5, 'lambda_l2': 21.29470551326328, 'colsample': 0.7704552439577235, 'subsample': 0.8694167768859007, 'min_gain_to_split': 42.77466640290896}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:53:34] Stdout logging level is INFO.\n",
      "[14:53:34] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:53:34] Iter 0; Sample 0, NLL-score = 8912.73382487772; \n",
      "[14:53:47] Early stopping at iter 194, best iter 174, best_score 7072.336286700116\n",
      "\u001b[32m[I 2022-12-05 14:53:47,557]\u001b[0m Trial 35 finished with value: 7072.33642578125 and parameters: {'lr': 0.39772007431611445, 'max_depth': 2, 'sketch_outputs': 4, 'lambda_l2': 37.11908051092486, 'colsample': 0.7108653245035685, 'subsample': 0.9410015103933486, 'min_gain_to_split': 206.4674421685255}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:53:47] Stdout logging level is INFO.\n",
      "[14:53:47] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:53:47] Iter 0; Sample 0, NLL-score = 9065.431460466883; \n",
      "[14:53:59] Early stopping at iter 176, best iter 156, best_score 7050.816919718092\n",
      "\u001b[32m[I 2022-12-05 14:53:59,802]\u001b[0m Trial 36 finished with value: 7050.8173828125 and parameters: {'lr': 0.11654969805551732, 'max_depth': 2, 'sketch_outputs': 7, 'lambda_l2': 0.6310780633049795, 'colsample': 0.8101932967563703, 'subsample': 0.4803708721031945, 'min_gain_to_split': 137.02303384036932}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:53:59] Stdout logging level is INFO.\n",
      "[14:53:59] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:53:59] Iter 0; Sample 0, NLL-score = 9167.418183355276; \n",
      "[14:54:09] Early stopping at iter 135, best iter 115, best_score 7049.199373666518\n",
      "\u001b[32m[I 2022-12-05 14:54:09,637]\u001b[0m Trial 37 finished with value: 7049.19921875 and parameters: {'lr': 0.20671584674304636, 'max_depth': 3, 'sketch_outputs': 6, 'lambda_l2': 27.302622026004645, 'colsample': 0.928013179245007, 'subsample': 0.657528414586863, 'min_gain_to_split': 88.90828189543802}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:54:09] Stdout logging level is INFO.\n",
      "[14:54:09] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:54:09] Iter 0; Sample 0, NLL-score = 8974.971431776787; \n",
      "[14:54:15] Early stopping at iter 91, best iter 71, best_score 7096.570326509302\n",
      "\u001b[32m[I 2022-12-05 14:54:15,353]\u001b[0m Trial 38 finished with value: 7096.5703125 and parameters: {'lr': 0.28397381537357885, 'max_depth': 2, 'sketch_outputs': 2, 'lambda_l2': 6.003391801522058, 'colsample': 0.8715550915950369, 'subsample': 0.42518432986953486, 'min_gain_to_split': 172.44898031552754}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:54:15] Stdout logging level is INFO.\n",
      "[14:54:15] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:54:15] Iter 0; Sample 0, NLL-score = 9176.54304013542; \n",
      "[14:54:35] Early stopping at iter 274, best iter 254, best_score 7042.8106031995085\n",
      "\u001b[32m[I 2022-12-05 14:54:35,587]\u001b[0m Trial 39 finished with value: 7042.810546875 and parameters: {'lr': 0.04793691572308788, 'max_depth': 3, 'sketch_outputs': 5, 'lambda_l2': 22.490576528572003, 'colsample': 0.9001798012438292, 'subsample': 0.7364732150686539, 'min_gain_to_split': 36.994553266835965}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:54:35] Stdout logging level is INFO.\n",
      "[14:54:35] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:54:35] Iter 0; Sample 0, NLL-score = 8874.781817195031; \n",
      "[14:54:40] Early stopping at iter 77, best iter 57, best_score 7109.458843615179\n",
      "\u001b[32m[I 2022-12-05 14:54:41,060]\u001b[0m Trial 40 finished with value: 7109.458984375 and parameters: {'lr': 0.4642809962752176, 'max_depth': 2, 'sketch_outputs': 4, 'lambda_l2': 12.05615340882566, 'colsample': 0.8328437475797004, 'subsample': 0.8161598453109012, 'min_gain_to_split': 113.64310900838976}. Best is trial 31 with value: 7030.70849609375.\u001b[0m\n",
      "[14:54:41] Stdout logging level is INFO.\n",
      "[14:54:41] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:54:41] Iter 0; Sample 0, NLL-score = 9223.519345310051; \n",
      "[14:55:15] Iter 499; Sample 0, NLL-score = 7030.154713530721; \n",
      "\u001b[32m[I 2022-12-05 14:55:16,653]\u001b[0m Trial 41 finished with value: 7030.154296875 and parameters: {'lr': 0.04788038202703776, 'max_depth': 2, 'sketch_outputs': 4, 'lambda_l2': 32.825156355387065, 'colsample': 0.938639132641955, 'subsample': 0.8066899140729238, 'min_gain_to_split': 75.73504633209573}. Best is trial 41 with value: 7030.154296875.\u001b[0m\n",
      "[14:55:16] Stdout logging level is INFO.\n",
      "[14:55:16] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:55:16] Iter 0; Sample 0, NLL-score = 9181.664358569626; \n",
      "[14:55:35] Early stopping at iter 275, best iter 255, best_score 7046.656396879024\n",
      "\u001b[32m[I 2022-12-05 14:55:35,538]\u001b[0m Trial 42 finished with value: 7046.65673828125 and parameters: {'lr': 0.12766295424404894, 'max_depth': 2, 'sketch_outputs': 3, 'lambda_l2': 35.193158274521345, 'colsample': 0.9433023910561501, 'subsample': 0.7753043618314707, 'min_gain_to_split': 67.8561385875501}. Best is trial 41 with value: 7030.154296875.\u001b[0m\n",
      "[14:55:35] Stdout logging level is INFO.\n",
      "[14:55:35] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:55:35] Iter 0; Sample 0, NLL-score = 9211.296028446273; \n",
      "[14:56:05] Early stopping at iter 432, best iter 412, best_score 7040.395868954326\n",
      "\u001b[32m[I 2022-12-05 14:56:06,133]\u001b[0m Trial 43 finished with value: 7040.39599609375 and parameters: {'lr': 0.05204514063863603, 'max_depth': 2, 'sketch_outputs': 4, 'lambda_l2': 37.78262195922001, 'colsample': 0.780959490712411, 'subsample': 0.5636940293205338, 'min_gain_to_split': 95.67226019870104}. Best is trial 41 with value: 7030.154296875.\u001b[0m\n",
      "[14:56:06] Stdout logging level is INFO.\n",
      "[14:56:06] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:56:06] Iter 0; Sample 0, NLL-score = 8990.327875870104; \n",
      "[14:56:19] Early stopping at iter 194, best iter 174, best_score 7041.234426308046\n",
      "\u001b[32m[I 2022-12-05 14:56:20,220]\u001b[0m Trial 44 finished with value: 7041.234375 and parameters: {'lr': 0.1773534224502412, 'max_depth': 2, 'sketch_outputs': 5, 'lambda_l2': 32.85274181048014, 'colsample': 0.8665858387393277, 'subsample': 0.8722227517313278, 'min_gain_to_split': 25.450423021936217}. Best is trial 41 with value: 7030.154296875.\u001b[0m\n",
      "[14:56:20] Stdout logging level is INFO.\n",
      "[14:56:20] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:56:20] Iter 0; Sample 0, NLL-score = 9227.680914183391; \n",
      "[14:56:48] Early stopping at iter 427, best iter 407, best_score 7036.851025082085\n",
      "\u001b[32m[I 2022-12-05 14:56:49,169]\u001b[0m Trial 45 finished with value: 7036.8505859375 and parameters: {'lr': 0.09188346456245747, 'max_depth': 2, 'sketch_outputs': 6, 'lambda_l2': 15.963285849988049, 'colsample': 0.9638521695206905, 'subsample': 0.9623149070767001, 'min_gain_to_split': 143.17921462775286}. Best is trial 41 with value: 7030.154296875.\u001b[0m\n",
      "[14:56:49] Stdout logging level is INFO.\n",
      "[14:56:49] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:56:49] Iter 0; Sample 0, NLL-score = 9279.485259398889; \n",
      "[14:57:24] Iter 499; Sample 0, NLL-score = 7924.237768283909; \n",
      "\u001b[32m[I 2022-12-05 14:57:25,766]\u001b[0m Trial 46 finished with value: 7924.23828125 and parameters: {'lr': 0.0033792339385932194, 'max_depth': 2, 'sketch_outputs': 2, 'lambda_l2': 30.111037928279412, 'colsample': 0.8960597059223201, 'subsample': 0.8082531174834066, 'min_gain_to_split': 3.161358359236704}. Best is trial 41 with value: 7030.154296875.\u001b[0m\n",
      "[14:57:25] Stdout logging level is INFO.\n",
      "[14:57:25] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:57:25] Iter 0; Sample 0, NLL-score = 9178.220194432242; \n",
      "[14:57:57] Iter 499; Sample 0, NLL-score = 7097.867876233099; \n",
      "\u001b[32m[I 2022-12-05 14:57:58,118]\u001b[0m Trial 47 finished with value: 7097.7939453125 and parameters: {'lr': 0.1424652684045768, 'max_depth': 1, 'sketch_outputs': 3, 'lambda_l2': 28.726882258774786, 'colsample': 0.49131749657483254, 'subsample': 0.746365158052041, 'min_gain_to_split': 55.87157979073853}. Best is trial 41 with value: 7030.154296875.\u001b[0m\n",
      "[14:57:58] Stdout logging level is INFO.\n",
      "[14:57:58] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:57:58] Iter 0; Sample 0, NLL-score = 8821.749771122853; \n",
      "[14:58:04] Early stopping at iter 93, best iter 73, best_score 7058.917591940659\n",
      "\u001b[32m[I 2022-12-05 14:58:04,399]\u001b[0m Trial 48 finished with value: 7058.91796875 and parameters: {'lr': 0.2736776435716354, 'max_depth': 3, 'sketch_outputs': 4, 'lambda_l2': 36.073286422482205, 'colsample': 0.6396404721839115, 'subsample': 0.9147531228776085, 'min_gain_to_split': 113.80669204220837}. Best is trial 41 with value: 7030.154296875.\u001b[0m\n",
      "[14:58:04] Stdout logging level is INFO.\n",
      "[14:58:04] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[14:58:04] Iter 0; Sample 0, NLL-score = 8985.337741945685; \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Specifies the hyper-parameters and their value range\n",
    "    # The structure is as follows: \"hyper-parameter\": [lower_bound, upper_bound]\n",
    "    # Currently, only the following hyper-parameters can be optimized\n",
    "    \n",
    "hp_dict = {\"lr\": [1e-3, 1],  \n",
    "           \"max_depth\": [1, 4],\n",
    "           \"sketch_outputs\": [1,10],\n",
    "           \"lambda_l2\": [0, 40],     \n",
    "           \"colsample\": [0.2, 1.0],\n",
    "           \"subsample\": [0.2, 1.0],\n",
    "           \"min_gain_to_split\": [0, 500]\n",
    "          }  \n",
    "\n",
    "opt_param = pyboostlss.hyper_opt(dist=distribution,\n",
    "                                 params=hp_dict,\n",
    "                                 dtrain=dtrain,\n",
    "                                 eval_sets=eval_sets,\n",
    "                                 use_hess=True, \n",
    "                                 sketch_method=\"proj\",\n",
    "                                 hp_seed=123,                # Seed for random number generator used in the Bayesian hyper-parameter search.\n",
    "                                 ntrees=500,                 # Number of boosting iterations.\n",
    "                                 es=20,                      # Early stopping rounds\n",
    "                                 n_trials=100,               # The number of trials. If this argument is set to None, there is no limitation on the number of trials.\n",
    "                                 max_minutes=120,            # Time budget in minutes, i.e., stop study after the given number of minutes.\n",
    "                                 silence=False)              # Controls the verbosity of the trail, i.e., user can silence the outputs of the trail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53213379-e7b1-4a4f-8d85-dda5a729f608",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9d38e-fee1-45fd-96cf-4ade74849593",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = opt_param.copy()\n",
    "\n",
    "pyboostlss_model = pyboostlss.train(dist=distribution, \n",
    "                                    dtrain=dtrain,\n",
    "                                    lr=opt_params[\"lr\"], \n",
    "                                    lambda_l2=opt_params[\"lambda_l2\"],\n",
    "                                    max_depth=opt_params[\"max_depth\"],\n",
    "                                    sketch_outputs=opt_params[\"sketch_outputs\"],\n",
    "                                    colsample=opt_params[\"colsample\"],\n",
    "                                    subsample=opt_params[\"subsample\"],\n",
    "                                    min_gain_to_split=opt_params[\"min_gain_to_split\"],\n",
    "                                    ntrees=opt_params[\"opt_rounds\"],\n",
    "                                    use_hess=True,\n",
    "                                    verbose=100,                                \n",
    "                                    sketch_method=\"proj\",\n",
    "                                    seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48228365-d49a-4481-868a-35b7e97535f5",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c126862-1732-4033-a24f-c9e5287fc1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts transformed parameters of the specified distribution. Py-BoostLSS returns the elements of the covariance matrix, instead of the Cholesky factors.\n",
    "predt_params = distribution.predict(model=pyboostlss_model,\n",
    "                                    X_test=x_test,\n",
    "                                    pred_type=\"parameters\")\n",
    "\n",
    "predt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1a565-b8a6-4864-861e-75a81d558528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draws random samples from the predicted distribution\n",
    "torch.manual_seed(123)\n",
    "predt_samples = distribution.predict(model=pyboostlss_model,\n",
    "                                     X_test=x_test,\n",
    "                                     pred_type=\"samples\",   \n",
    "                                     n_samples=1000)\n",
    "\n",
    "predt_samples.shape # Output shape is (n_samples, n_obs, n_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dcd82-94fa-409d-8f62-db9bc7037c98",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178932c6-32b8-4b45-a264-db6844e62d7d",
   "metadata": {},
   "source": [
    "In the following, we compare the true moments of the multivariate Gaussian with the ones predicted by Py-BoostLSS. The below figure shows that the estimated parameters of the multivariate Gaussian closely match the true parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79d446-6617-46ce-ae8b-c5209f26abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predt_params[\"x\"] = x_test\n",
    "dist_params = list(predt_params.columns)\n",
    "drop_cols = [resp for resp in list(data_sim.columns) if \"y\" in resp]\n",
    "\n",
    "# Data with actual values\n",
    "plot_df_actual = pd.melt(data_sim.drop(columns=drop_cols, axis=0),\n",
    "                         id_vars=\"x\",\n",
    "                         value_vars=dist_params)\n",
    "plot_df_actual[\"type\"] = \"ACTUAL\"\n",
    "\n",
    "# Data with predicted values\n",
    "plot_df_predt = pd.melt(predt_params,\n",
    "                        id_vars=\"x\",\n",
    "                        value_vars=dist_params)\n",
    "plot_df_predt[\"type\"] = \"FIT\"\n",
    "\n",
    "plot_df = pd.concat([plot_df_actual, plot_df_predt])   \n",
    "\n",
    "plot_df[\"variable\"] = plot_df.variable.str.upper()\n",
    "\n",
    "\n",
    "plot_params = (ggplot(plot_df,\n",
    "                      aes(x=\"x\",\n",
    "                          y=\"value\",\n",
    "                          color=\"type\")) +\n",
    "               geom_line(size=1.1) + \n",
    "               facet_wrap(\"variable\",\n",
    "                          scales=\"free\") + \n",
    "               labs(title=\"Parameters of Trivariate-Gaussian estimated with Py-BoostLSS using Cholesky-Decomposition of Covariance-Matrix\\n\",\n",
    "                    x=\"\",\n",
    "                    y=\"\") + \n",
    "               theme_bw(base_size=15) + \n",
    "               theme(legend_position=\"bottom\",\n",
    "                     legend_title = element_blank(),\n",
    "                     subplots_adjust={\"wspace\": 0.25,\n",
    "                                      \"hspace\": 0.45})\n",
    "              )\n",
    "\n",
    "\n",
    "print(plot_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
