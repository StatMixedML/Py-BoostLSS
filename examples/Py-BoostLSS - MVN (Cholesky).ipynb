{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7b4eea0-96b6-482a-afc9-7ec867bf2193",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de768b2-ef44-434d-89e4-402170de0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from pyboostlss.model import *\n",
    "from pyboostlss.distributions.MVN import *\n",
    "from pyboostlss.distributions.distribution_loss_metric import *\n",
    "from pyboostlss.utils import *\n",
    "from pyboostlss.datasets.data_loader import load_simulated_data\n",
    "\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "plotnine.options.figure_size = (20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e90e9e4-5902-4299-9236-d31af4e29b2b",
   "metadata": {},
   "source": [
    "# Specifiy Distribtution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75224245-9b11-4730-a4c6-d7fe6b3a272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = MVN(D=3) # Multivariate Normal, where D specifies the number of target variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b7e46a-1019-4bd8-8e79-cd958316bf76",
   "metadata": {},
   "source": [
    "In this example, we model and predict all parameters of a trivariate Gaussian. The conditional means $\\mathbf{\\mu} (x)$ and the conditional covariance matrix $\\mathbf{\\Sigma}(x)$ are given as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3505891-bf03-4f01-9456-71790adc323e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{\\mu}(x)=\\begin{pmatrix}\\mu_{1}(x) \\\\ \\mu_{2}(x) \\\\ \\mu_{3}(x)\\end{pmatrix}, \\qquad \\qquad  \n",
    "\\mathbf{\\Sigma}(x)= \\begin{pmatrix}\n",
    "\\sigma^{2}_{11}(x) & \\rho_{1,2}(x)\\sigma_{1}(x)\\sigma_{2}(x) & \\rho_{1,3}(x)\\sigma_{1}(x)\\sigma_{3}(x) \\\\\n",
    "\\rho_{2,1}(x)\\sigma_{2}(x)\\sigma_{1}(x) & \\sigma^{2}_{22}(x) & \\rho_{2,3}(x)\\sigma_{2}(x)\\sigma_{3}(x) \\\\\n",
    "\\rho_{3,1}(x)\\sigma_{3}(x)\\sigma_{1}(x) & \\rho_{3,2}(x)\\sigma_{3}(x)\\sigma_{2}(x) &  \\sigma^{2}_{33}(x)\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ca5ba-f094-4f6f-a615-37919c0c7bbf",
   "metadata": {},
   "source": [
    "Ensuring positive definiteness of the covariance matrix $\\Sigma$ becomes challenging, since joint restrictions for the elements are necessary. A computationally more tractable approach to ensure positive definiteness is based on the Cholesky decomposition, that uniquely decomposes the covariance matrix as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fca4c-6669-4d44-8080-5828f3cce375",
   "metadata": {},
   "source": [
    "$$\\mathbf{\\Sigma}(x) = \\mathbf{L}(x) \\mathbf{L}^{\\prime}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d06fba-4887-46af-a1e9-44bc7c91af68",
   "metadata": {},
   "source": [
    "where $\\mathbf{}L(\\cdot)$ is a lower triangular matrix with positive diagonal entries. Instead of estimating the entries of $\\mathbf{\\Sigma}(\\cdot)$ directly, Py-BoostLSS estimates the Cholesky factors $\\mathbf{L}(\\cdot)$ and then uses these for creating $\\mathbf{\\Sigma}(\\cdot)$. For more details, we refer to **MÃ¤rz, Alexander (2022) [*Multi-Target XGBoostLSS Regression*](https://arxiv.org/abs/2210.06831)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c36cd5-11f4-4c03-8297-c2555924bd4a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78118dfc-6b05-4634-ae15-9fbf3d30b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sim = load_simulated_data(\"sim_triv_gaussian.csv\")\n",
    "\n",
    "# Create 60%, 20%, 20% split for train, validation and test \n",
    "train, validate, test = np.split(data_sim.sample(frac=1,random_state=123), [int(0.6*len(data_sim)), int(0.8*len(data_sim))])\n",
    "\n",
    "# Train\n",
    "x_train = train[\"x\"].values.reshape(-1,1)\n",
    "y_train = train.filter(regex=\"y\").values\n",
    "dtrain = {\"X\": x_train, \"y\": y_train}\n",
    "\n",
    "# Validation\n",
    "x_eval = validate[\"x\"].values.reshape(-1,1)\n",
    "y_eval = validate.filter(regex=\"y\").values\n",
    "eval_sets = [{'X': x_eval, 'y': y_eval}] # Specifies eval_sets on which the model is evaluated on\n",
    "\n",
    "# Test\n",
    "x_test = test[\"x\"].values.reshape(-1,1)\n",
    "y_test = test.filter(regex=\"y\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e742234a-ad21-4a32-aa80-08c59d318503",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Optimization via Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8403d-ea56-4d44-ba26-1f86632b7b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-05 12:53:16,460]\u001b[0m A new study created in memory with name: Py-BoostLSS Hyper-Parameter Optimization\u001b[0m\n",
      "C:\\Users\\Alexander\\.julia\\v0.6\\Conda\\deps\\usr\\envs\\pyboost\\lib\\site-packages\\optuna\\progress_bar.py:49: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4226013fbf4f50b47d76646289bdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:53:23] Stdout logging level is INFO.\n",
      "[12:53:23] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:53:25] Iter 0; Sample 0, NLL-score = 9176.23200749895; \n",
      "[12:53:31] Early stopping at iter 86, best iter 66, best_score 7150.972203020752\n",
      "\u001b[32m[I 2022-12-05 12:53:31,364]\u001b[0m Trial 0 finished with value: 7150.97216796875 and parameters: {'lr': 0.5605976584742175, 'max_depth': 4, 'sketch_outputs': 1, 'lambda_l2': 8.125403616631655, 'colsample': 0.606262867277662, 'subsample': 0.6447004814948847, 'min_gain_to_split': 224.0643041445496}. Best is trial 0 with value: 7150.97216796875.\u001b[0m\n",
      "[12:53:31] Stdout logging level is INFO.\n",
      "[12:53:31] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:53:31] Iter 0; Sample 0, NLL-score = 8604.834479917325; \n",
      "[12:53:34] Early stopping at iter 44, best iter 24, best_score 7272.111076333547\n",
      "\u001b[32m[I 2022-12-05 12:53:34,395]\u001b[0m Trial 1 finished with value: 7272.111328125 and parameters: {'lr': 0.7225739525097444, 'max_depth': 3, 'sketch_outputs': 10, 'lambda_l2': 30.991713189661635, 'colsample': 0.7431839092905947, 'subsample': 0.2627948646972744, 'min_gain_to_split': 196.33135638175065}. Best is trial 0 with value: 7150.97216796875.\u001b[0m\n",
      "[12:53:34] Stdout logging level is INFO.\n",
      "[12:53:34] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:53:34] Iter 0; Sample 0, NLL-score = 9046.356083955763; \n",
      "[12:54:04] Iter 499; Sample 0, NLL-score = 7071.327541352424; \n",
      "\u001b[32m[I 2022-12-05 12:54:05,275]\u001b[0m Trial 2 finished with value: 7069.9013671875 and parameters: {'lr': 0.42928639376070815, 'max_depth': 1, 'sketch_outputs': 2, 'lambda_l2': 17.904901299380054, 'colsample': 0.4000579548959071, 'subsample': 0.7259478563520176, 'min_gain_to_split': 356.1926474407537}. Best is trial 2 with value: 7069.9013671875.\u001b[0m\n",
      "[12:54:05] Stdout logging level is INFO.\n",
      "[12:54:05] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:54:05] Iter 0; Sample 0, NLL-score = 9209.56408670485; \n",
      "[12:54:35] Iter 499; Sample 0, NLL-score = 7088.384142195748; \n",
      "\u001b[32m[I 2022-12-05 12:54:36,149]\u001b[0m Trial 3 finished with value: 7088.31640625 and parameters: {'lr': 0.14412285670149363, 'max_depth': 1, 'sketch_outputs': 5, 'lambda_l2': 39.661959281769455, 'colsample': 0.5425388469706496, 'subsample': 0.5111263263893733, 'min_gain_to_split': 70.94246338668658}. Best is trial 2 with value: 7069.9013671875.\u001b[0m\n",
      "[12:54:36] Stdout logging level is INFO.\n",
      "[12:54:36] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:54:36] Iter 0; Sample 0, NLL-score = 8557.679913396543; \n",
      "[12:54:39] Early stopping at iter 45, best iter 25, best_score 7099.708560896037\n",
      "\u001b[32m[I 2022-12-05 12:54:39,637]\u001b[0m Trial 4 finished with value: 7099.70849609375 and parameters: {'lr': 0.3804267952866905, 'max_depth': 3, 'sketch_outputs': 10, 'lambda_l2': 2.4594448504904953, 'colsample': 0.9082096963499329, 'subsample': 0.6969422585598181, 'min_gain_to_split': 42.591779211677725}. Best is trial 2 with value: 7069.9013671875.\u001b[0m\n",
      "[12:54:39] Stdout logging level is INFO.\n",
      "[12:54:39] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:54:39] Iter 0; Sample 0, NLL-score = 8476.846242432068; \n",
      "[12:54:43] Early stopping at iter 41, best iter 21, best_score 7153.111085972159\n",
      "\u001b[32m[I 2022-12-05 12:54:43,121]\u001b[0m Trial 5 finished with value: 7153.111328125 and parameters: {'lr': 0.5131602492400366, 'max_depth': 4, 'sketch_outputs': 4, 'lambda_l2': 5.833124275523391, 'colsample': 0.49388482367554254, 'subsample': 0.8806950960077726, 'min_gain_to_split': 359.9603203944147}. Best is trial 2 with value: 7069.9013671875.\u001b[0m\n",
      "[12:54:43] Stdout logging level is INFO.\n",
      "[12:54:43] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:54:43] Iter 0; Sample 0, NLL-score = 8789.943183173451; \n",
      "[12:54:56] Early stopping at iter 190, best iter 170, best_score 7050.002371419849\n",
      "\u001b[32m[I 2022-12-05 12:54:56,791]\u001b[0m Trial 6 finished with value: 7050.00244140625 and parameters: {'lr': 0.30690349118600047, 'max_depth': 2, 'sketch_outputs': 7, 'lambda_l2': 10.361293963944846, 'colsample': 0.6815908161287526, 'subsample': 0.6978400666681253, 'min_gain_to_split': 208.1159704833947}. Best is trial 6 with value: 7050.00244140625.\u001b[0m\n",
      "[12:54:56] Stdout logging level is INFO.\n",
      "[12:54:56] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:54:56] Iter 0; Sample 0, NLL-score = 9192.75107741146; \n",
      "[12:55:31] Iter 499; Sample 0, NLL-score = 7052.653559906225; \n",
      "\u001b[32m[I 2022-12-05 12:55:31,775]\u001b[0m Trial 7 finished with value: 7052.65380859375 and parameters: {'lr': 0.06713570341216024, 'max_depth': 2, 'sketch_outputs': 2, 'lambda_l2': 4.722715627116072, 'colsample': 0.583662705487173, 'subsample': 0.7375203370584675, 'min_gain_to_split': 344.14480102363456}. Best is trial 6 with value: 7050.00244140625.\u001b[0m\n",
      "[12:55:31] Stdout logging level is INFO.\n",
      "[12:55:31] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:55:31] Iter 0; Sample 0, NLL-score = 8572.293937458904; \n",
      "[12:55:36] Early stopping at iter 59, best iter 39, best_score 7252.116489518793\n",
      "\u001b[32m[I 2022-12-05 12:55:36,295]\u001b[0m Trial 8 finished with value: 7252.11669921875 and parameters: {'lr': 0.8735433774168309, 'max_depth': 3, 'sketch_outputs': 7, 'lambda_l2': 29.275179301521984, 'colsample': 0.29978441334740824, 'subsample': 0.45474235271354235, 'min_gain_to_split': 359.11094551599416}. Best is trial 6 with value: 7050.00244140625.\u001b[0m\n",
      "[12:55:36] Stdout logging level is INFO.\n",
      "[12:55:36] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:55:36] Iter 0; Sample 0, NLL-score = 8599.358730652493; \n",
      "[12:55:41] Early stopping at iter 79, best iter 59, best_score 7337.368486311145\n",
      "\u001b[32m[I 2022-12-05 12:55:41,942]\u001b[0m Trial 9 finished with value: 7337.36865234375 and parameters: {'lr': 0.8995202587735721, 'max_depth': 2, 'sketch_outputs': 7, 'lambda_l2': 17.57557119122904, 'colsample': 0.2945143780100013, 'subsample': 0.4910597767158333, 'min_gain_to_split': 122.2872449503003}. Best is trial 6 with value: 7050.00244140625.\u001b[0m\n",
      "[12:55:41] Stdout logging level is INFO.\n",
      "[12:55:41] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:55:42] Iter 0; Sample 0, NLL-score = 8993.745489842246; \n",
      "[12:56:04] Early stopping at iter 335, best iter 315, best_score 7036.683083222965\n",
      "\u001b[32m[I 2022-12-05 12:56:04,543]\u001b[0m Trial 10 finished with value: 7036.68359375 and parameters: {'lr': 0.198411880676512, 'max_depth': 2, 'sketch_outputs': 8, 'lambda_l2': 12.166981308026875, 'colsample': 0.9978530443005473, 'subsample': 0.9975840612823647, 'min_gain_to_split': 463.897193858449}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:56:04] Stdout logging level is INFO.\n",
      "[12:56:04] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:56:04] Iter 0; Sample 0, NLL-score = 8941.875241907635; \n",
      "[12:56:19] Early stopping at iter 227, best iter 207, best_score 7041.309794047633\n",
      "\u001b[32m[I 2022-12-05 12:56:19,580]\u001b[0m Trial 11 finished with value: 7041.3095703125 and parameters: {'lr': 0.24744934865577842, 'max_depth': 2, 'sketch_outputs': 8, 'lambda_l2': 12.824697185696504, 'colsample': 0.9899263611313481, 'subsample': 0.9830704718301779, 'min_gain_to_split': 495.0695785428604}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:56:19] Stdout logging level is INFO.\n",
      "[12:56:19] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:56:19] Iter 0; Sample 0, NLL-score = 8965.454907302335; \n",
      "[12:56:33] Early stopping at iter 206, best iter 186, best_score 7050.167823455806\n",
      "\u001b[32m[I 2022-12-05 12:56:33,323]\u001b[0m Trial 12 finished with value: 7050.16748046875 and parameters: {'lr': 0.22472211701759717, 'max_depth': 2, 'sketch_outputs': 8, 'lambda_l2': 12.814332715774706, 'colsample': 0.9794632921962674, 'subsample': 0.9826633871291135, 'min_gain_to_split': 495.47251001896365}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:56:33] Stdout logging level is INFO.\n",
      "[12:56:33] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:56:33] Iter 0; Sample 0, NLL-score = 9276.564565114606; \n",
      "[12:57:03] Iter 499; Sample 0, NLL-score = 8077.159129777146; \n",
      "\u001b[32m[I 2022-12-05 12:57:03,773]\u001b[0m Trial 13 finished with value: 8077.1591796875 and parameters: {'lr': 0.010670869471526845, 'max_depth': 1, 'sketch_outputs': 9, 'lambda_l2': 22.198084646357792, 'colsample': 0.8467584886461179, 'subsample': 0.9987631049747805, 'min_gain_to_split': 495.2924201734305}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:57:03] Stdout logging level is INFO.\n",
      "[12:57:03] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:57:03] Iter 0; Sample 0, NLL-score = 8955.777767275624; \n",
      "[12:57:17] Early stopping at iter 203, best iter 183, best_score 7045.99619777714\n",
      "\u001b[32m[I 2022-12-05 12:57:18,209]\u001b[0m Trial 14 finished with value: 7045.99658203125 and parameters: {'lr': 0.23390717510380557, 'max_depth': 2, 'sketch_outputs': 8, 'lambda_l2': 13.817188710538806, 'colsample': 0.8072260547351159, 'subsample': 0.8610883216669826, 'min_gain_to_split': 432.12070461379966}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:57:18] Stdout logging level is INFO.\n",
      "[12:57:18] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:57:18] Iter 0; Sample 0, NLL-score = 8958.600657980169; \n",
      "[12:57:29] Early stopping at iter 157, best iter 137, best_score 7070.774735771568\n",
      "\u001b[32m[I 2022-12-05 12:57:30,165]\u001b[0m Trial 15 finished with value: 7070.7744140625 and parameters: {'lr': 0.1610492755193139, 'max_depth': 3, 'sketch_outputs': 5, 'lambda_l2': 24.534703430723354, 'colsample': 0.981348773693029, 'subsample': 0.8571851129975394, 'min_gain_to_split': 425.4019623453395}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:57:30] Stdout logging level is INFO.\n",
      "[12:57:30] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:57:30] Iter 0; Sample 0, NLL-score = 9094.420517559965; \n",
      "[12:57:43] Early stopping at iter 204, best iter 184, best_score 7166.692385322089\n",
      "\u001b[32m[I 2022-12-05 12:57:43,301]\u001b[0m Trial 16 finished with value: 7166.6923828125 and parameters: {'lr': 0.6201689218801818, 'max_depth': 1, 'sketch_outputs': 6, 'lambda_l2': 0.08094897960867797, 'colsample': 0.8704932570775373, 'subsample': 0.8978876060392075, 'min_gain_to_split': 289.218660671216}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:57:43] Stdout logging level is INFO.\n",
      "[12:57:43] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:57:43] Iter 0; Sample 0, NLL-score = 9087.121900908318; \n",
      "[12:57:48] Early stopping at iter 79, best iter 59, best_score 7103.3623253624355\n",
      "\u001b[32m[I 2022-12-05 12:57:48,988]\u001b[0m Trial 17 finished with value: 7103.3623046875 and parameters: {'lr': 0.3385104150081475, 'max_depth': 2, 'sketch_outputs': 9, 'lambda_l2': 14.439862043630475, 'colsample': 0.7269898191401554, 'subsample': 0.25035808194609743, 'min_gain_to_split': 426.68352021786893}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:57:49] Stdout logging level is INFO.\n",
      "[12:57:49] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:57:49] Iter 0; Sample 0, NLL-score = 9049.315621639937; \n",
      "[12:58:01] Early stopping at iter 168, best iter 148, best_score 7049.055376399972\n",
      "\u001b[32m[I 2022-12-05 12:58:02,124]\u001b[0m Trial 18 finished with value: 7049.0556640625 and parameters: {'lr': 0.12810232054006798, 'max_depth': 3, 'sketch_outputs': 8, 'lambda_l2': 25.8870832492155, 'colsample': 0.9745594683624272, 'subsample': 0.7933768716063315, 'min_gain_to_split': 456.7846433461566}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:58:02] Stdout logging level is INFO.\n",
      "[12:58:02] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:58:02] Iter 0; Sample 0, NLL-score = 9162.125084302605; \n",
      "[12:58:34] Iter 499; Sample 0, NLL-score = 7063.279480075549; \n",
      "\u001b[32m[I 2022-12-05 12:58:34,714]\u001b[0m Trial 19 finished with value: 7063.279296875 and parameters: {'lr': 0.27090434162489724, 'max_depth': 1, 'sketch_outputs': 4, 'lambda_l2': 9.002348622400849, 'colsample': 0.7872299570102139, 'subsample': 0.9421263977286001, 'min_gain_to_split': 300.1114442147618}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:58:34] Stdout logging level is INFO.\n",
      "[12:58:34] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:58:34] Iter 0; Sample 0, NLL-score = 9126.05881564211; \n",
      "[12:58:43] Early stopping at iter 130, best iter 110, best_score 7055.976397805715\n",
      "\u001b[32m[I 2022-12-05 12:58:43,231]\u001b[0m Trial 20 finished with value: 7055.9765625 and parameters: {'lr': 0.40238548873905144, 'max_depth': 2, 'sketch_outputs': 6, 'lambda_l2': 20.41527449604414, 'colsample': 0.8985244858550278, 'subsample': 0.8165338641965136, 'min_gain_to_split': 148.2668324263745}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:58:43] Stdout logging level is INFO.\n",
      "[12:58:43] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:58:43] Iter 0; Sample 0, NLL-score = 8969.594823531072; \n",
      "[12:58:59] Early stopping at iter 258, best iter 238, best_score 7050.388695788866\n",
      "\u001b[32m[I 2022-12-05 12:58:59,917]\u001b[0m Trial 21 finished with value: 7050.388671875 and parameters: {'lr': 0.2205295827560676, 'max_depth': 2, 'sketch_outputs': 8, 'lambda_l2': 14.174489652870891, 'colsample': 0.8208368269206767, 'subsample': 0.9283170668913565, 'min_gain_to_split': 422.09576952015954}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:58:59] Stdout logging level is INFO.\n",
      "[12:58:59] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:59:00] Iter 0; Sample 0, NLL-score = 9273.394602755605; \n",
      "[12:59:34] Iter 499; Sample 0, NLL-score = 7133.60592048724; \n",
      "\u001b[32m[I 2022-12-05 12:59:35,353]\u001b[0m Trial 22 finished with value: 7133.60595703125 and parameters: {'lr': 0.014010677372586017, 'max_depth': 2, 'sketch_outputs': 9, 'lambda_l2': 12.459318173230963, 'colsample': 0.9404598410500957, 'subsample': 0.9998052337193799, 'min_gain_to_split': 460.82842624983505}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:59:35] Stdout logging level is INFO.\n",
      "[12:59:35] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:59:35] Iter 0; Sample 0, NLL-score = 8955.52811385559; \n",
      "[12:59:50] Early stopping at iter 203, best iter 183, best_score 7051.091995242965\n",
      "\u001b[32m[I 2022-12-05 12:59:50,453]\u001b[0m Trial 23 finished with value: 7051.091796875 and parameters: {'lr': 0.23611157024799376, 'max_depth': 2, 'sketch_outputs': 8, 'lambda_l2': 17.49954135403192, 'colsample': 0.9974529398186367, 'subsample': 0.8189459725416248, 'min_gain_to_split': 408.0542883914617}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:59:50] Stdout logging level is INFO.\n",
      "[12:59:50] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:59:50] Iter 0; Sample 0, NLL-score = 8518.218580946083; \n",
      "[12:59:57] Early stopping at iter 89, best iter 69, best_score 7084.570916981576\n",
      "\u001b[32m[I 2022-12-05 12:59:57,723]\u001b[0m Trial 24 finished with value: 7084.5712890625 and parameters: {'lr': 0.4597451592964091, 'max_depth': 3, 'sketch_outputs': 10, 'lambda_l2': 6.764014354189564, 'colsample': 0.7868537070402669, 'subsample': 0.9318319594356248, 'min_gain_to_split': 497.9906209003738}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[12:59:57] Stdout logging level is INFO.\n",
      "[12:59:57] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[12:59:57] Iter 0; Sample 0, NLL-score = 9089.860608328796; \n",
      "[13:00:22] Early stopping at iter 358, best iter 338, best_score 7046.971828952059\n",
      "\u001b[32m[I 2022-12-05 13:00:23,492]\u001b[0m Trial 25 finished with value: 7046.9716796875 and parameters: {'lr': 0.09777831423346564, 'max_depth': 2, 'sketch_outputs': 7, 'lambda_l2': 10.993217078499432, 'colsample': 0.6688974699929718, 'subsample': 0.5978266192621953, 'min_gain_to_split': 394.05284105418696}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:00:23] Stdout logging level is INFO.\n",
      "[13:00:23] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:00:23] Iter 0; Sample 0, NLL-score = 9098.631327063338; \n",
      "[13:00:56] Iter 499; Sample 0, NLL-score = 7046.705513082468; \n",
      "\u001b[32m[I 2022-12-05 13:00:57,011]\u001b[0m Trial 26 finished with value: 7046.2724609375 and parameters: {'lr': 0.329345795857106, 'max_depth': 1, 'sketch_outputs': 9, 'lambda_l2': 14.533772342946738, 'colsample': 0.9160976881648808, 'subsample': 0.8621761393764122, 'min_gain_to_split': 461.76658146340077}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:00:57] Stdout logging level is INFO.\n",
      "[13:00:57] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:00:57] Iter 0; Sample 0, NLL-score = 9068.31180882185; \n",
      "[13:01:04] Early stopping at iter 99, best iter 79, best_score 7300.689133397088\n",
      "\u001b[32m[I 2022-12-05 13:01:04,969]\u001b[0m Trial 27 finished with value: 7300.689453125 and parameters: {'lr': 0.9956642724058279, 'max_depth': 2, 'sketch_outputs': 6, 'lambda_l2': 16.958603093990444, 'colsample': 0.852554874740269, 'subsample': 0.7905893297868706, 'min_gain_to_split': 302.3161322119747}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:01:05] Stdout logging level is INFO.\n",
      "[13:01:05] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:01:05] Iter 0; Sample 0, NLL-score = 8902.012486909629; \n",
      "[13:01:16] Early stopping at iter 136, best iter 116, best_score 7065.457474670597\n",
      "\u001b[32m[I 2022-12-05 13:01:16,916]\u001b[0m Trial 28 finished with value: 7065.45751953125 and parameters: {'lr': 0.18735538284301723, 'max_depth': 3, 'sketch_outputs': 8, 'lambda_l2': 22.138157442361248, 'colsample': 0.9307905913727353, 'subsample': 0.3743052883247125, 'min_gain_to_split': 389.1663428227123}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:01:16] Stdout logging level is INFO.\n",
      "[13:01:16] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:01:17] Iter 0; Sample 0, NLL-score = 8661.126395194444; \n",
      "[13:01:20] Early stopping at iter 34, best iter 14, best_score 7144.900271443342\n",
      "\u001b[32m[I 2022-12-05 13:01:20,069]\u001b[0m Trial 29 finished with value: 7144.900390625 and parameters: {'lr': 0.5947923037810081, 'max_depth': 4, 'sketch_outputs': 9, 'lambda_l2': 8.392792096947462, 'colsample': 0.6572494959242619, 'subsample': 0.9471639786372514, 'min_gain_to_split': 263.6494305905696}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:01:20] Stdout logging level is INFO.\n",
      "[13:01:20] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:01:20] Iter 0; Sample 0, NLL-score = 9007.889765786858; \n",
      "[13:01:38] Early stopping at iter 272, best iter 252, best_score 7097.076496991493\n",
      "\u001b[32m[I 2022-12-05 13:01:38,501]\u001b[0m Trial 30 finished with value: 7097.076171875 and parameters: {'lr': 0.51933963578362, 'max_depth': 1, 'sketch_outputs': 7, 'lambda_l2': 4.268843769616833, 'colsample': 0.7998086291363362, 'subsample': 0.6075312270353671, 'min_gain_to_split': 446.29075190463755}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:01:38] Stdout logging level is INFO.\n",
      "[13:01:38] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:01:38] Iter 0; Sample 0, NLL-score = 9098.471281712045; \n",
      "[13:02:09] Early stopping at iter 487, best iter 467, best_score 7045.1070766950725\n",
      "\u001b[32m[I 2022-12-05 13:02:09,619]\u001b[0m Trial 31 finished with value: 7045.10693359375 and parameters: {'lr': 0.32876253722904447, 'max_depth': 1, 'sketch_outputs': 9, 'lambda_l2': 14.874024364009134, 'colsample': 0.9165335608384189, 'subsample': 0.8413974731316746, 'min_gain_to_split': 466.89202237346353}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:02:09] Stdout logging level is INFO.\n",
      "[13:02:09] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:02:09] Iter 0; Sample 0, NLL-score = 9101.103053045023; \n",
      "[13:02:41] Early stopping at iter 486, best iter 466, best_score 7054.456640916468\n",
      "\u001b[32m[I 2022-12-05 13:02:42,409]\u001b[0m Trial 32 finished with value: 7054.45703125 and parameters: {'lr': 0.26960572094645346, 'max_depth': 1, 'sketch_outputs': 10, 'lambda_l2': 10.7458533950454, 'colsample': 0.9442719580456868, 'subsample': 0.8524237813150038, 'min_gain_to_split': 461.7035217963862}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:02:42] Stdout logging level is INFO.\n",
      "[13:02:42] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:02:42] Iter 0; Sample 0, NLL-score = 8876.224035813975; \n",
      "[13:02:56] Early stopping at iter 204, best iter 184, best_score 7061.394827962463\n",
      "\u001b[32m[I 2022-12-05 13:02:56,287]\u001b[0m Trial 33 finished with value: 7061.3955078125 and parameters: {'lr': 0.32414016746816865, 'max_depth': 2, 'sketch_outputs': 8, 'lambda_l2': 15.685632612687769, 'colsample': 0.7498235800385878, 'subsample': 0.7596765680434948, 'min_gain_to_split': 390.5904934868137}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:02:56] Stdout logging level is INFO.\n",
      "[13:02:56] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:02:56] Iter 0; Sample 0, NLL-score = 9078.487654755025; \n",
      "[13:03:27] Iter 499; Sample 0, NLL-score = 7062.744374806665; \n",
      "\u001b[32m[I 2022-12-05 13:03:27,945]\u001b[0m Trial 34 finished with value: 7062.744140625 and parameters: {'lr': 0.3679482386775518, 'max_depth': 1, 'sketch_outputs': 9, 'lambda_l2': 19.935104026239973, 'colsample': 0.2118735232833837, 'subsample': 0.9117964098800047, 'min_gain_to_split': 475.6233328975019}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:03:27] Stdout logging level is INFO.\n",
      "[13:03:28] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:03:28] Iter 0; Sample 0, NLL-score = 9017.302468440252; \n",
      "[13:03:52] Early stopping at iter 382, best iter 362, best_score 7062.273541494449\n",
      "\u001b[32m[I 2022-12-05 13:03:52,958]\u001b[0m Trial 35 finished with value: 7062.2734375 and parameters: {'lr': 0.45859966786068007, 'max_depth': 1, 'sketch_outputs': 10, 'lambda_l2': 35.73850010683485, 'colsample': 0.872169593764337, 'subsample': 0.9609275549482557, 'min_gain_to_split': 439.9093414771955}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:03:53] Stdout logging level is INFO.\n",
      "[13:03:53] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:03:53] Iter 0; Sample 0, NLL-score = 9283.674332795832; \n",
      "[13:04:15] Early stopping at iter 333, best iter 313, best_score 7080.054818686322\n",
      "\u001b[32m[I 2022-12-05 13:04:15,581]\u001b[0m Trial 36 finished with value: 7080.05517578125 and parameters: {'lr': 0.1767493184336964, 'max_depth': 2, 'sketch_outputs': 1, 'lambda_l2': 19.98984386562992, 'colsample': 0.8978397810026089, 'subsample': 0.8929424960115189, 'min_gain_to_split': 323.04721024653236}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:04:15] Stdout logging level is INFO.\n",
      "[13:04:15] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:04:15] Iter 0; Sample 0, NLL-score = 8848.562327218047; \n",
      "[13:04:20] Early stopping at iter 66, best iter 46, best_score 7060.032450859622\n",
      "\u001b[32m[I 2022-12-05 13:04:20,944]\u001b[0m Trial 37 finished with value: 7060.0322265625 and parameters: {'lr': 0.27410804791091564, 'max_depth': 3, 'sketch_outputs': 10, 'lambda_l2': 12.456806920535271, 'colsample': 0.4794268641325423, 'subsample': 0.6531141085183935, 'min_gain_to_split': 382.7772335201678}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:04:21] Stdout logging level is INFO.\n",
      "[13:04:21] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:04:21] Iter 0; Sample 0, NLL-score = 9102.508987537443; \n",
      "[13:04:30] Early stopping at iter 119, best iter 99, best_score 7055.190875693708\n",
      "\u001b[32m[I 2022-12-05 13:04:30,941]\u001b[0m Trial 38 finished with value: 7055.19091796875 and parameters: {'lr': 0.06435950402590862, 'max_depth': 4, 'sketch_outputs': 8, 'lambda_l2': 7.11578834250437, 'colsample': 0.9463197883102477, 'subsample': 0.8384809453435699, 'min_gain_to_split': 479.9922142407026}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:04:31] Stdout logging level is INFO.\n",
      "[13:04:31] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:04:31] Iter 0; Sample 0, NLL-score = 8685.984079047383; \n",
      "[13:04:36] Early stopping at iter 76, best iter 56, best_score 7122.496655838531\n",
      "\u001b[32m[I 2022-12-05 13:04:36,563]\u001b[0m Trial 39 finished with value: 7122.4970703125 and parameters: {'lr': 0.4081613414495532, 'max_depth': 2, 'sketch_outputs': 7, 'lambda_l2': 10.34750470796741, 'colsample': 0.7360994174711022, 'subsample': 0.331405193366141, 'min_gain_to_split': 6.9234117771740955}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:04:36] Stdout logging level is INFO.\n",
      "[13:04:36] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:04:36] Iter 0; Sample 0, NLL-score = 9110.431289815042; \n",
      "[13:04:55] Early stopping at iter 313, best iter 293, best_score 7169.688427140829\n",
      "\u001b[32m[I 2022-12-05 13:04:56,250]\u001b[0m Trial 40 finished with value: 7169.6884765625 and parameters: {'lr': 0.7197057832323663, 'max_depth': 1, 'sketch_outputs': 4, 'lambda_l2': 2.7028404855616373, 'colsample': 0.8331512724819444, 'subsample': 0.6921110652758379, 'min_gain_to_split': 334.00166927026316}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:04:56] Stdout logging level is INFO.\n",
      "[13:04:56] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:04:56] Iter 0; Sample 0, NLL-score = 9106.787829743738; \n",
      "[13:05:28] Iter 499; Sample 0, NLL-score = 7051.8596302656015; \n",
      "\u001b[32m[I 2022-12-05 13:05:29,237]\u001b[0m Trial 41 finished with value: 7051.2919921875 and parameters: {'lr': 0.31057459466765114, 'max_depth': 1, 'sketch_outputs': 9, 'lambda_l2': 14.97331008707717, 'colsample': 0.907178701839923, 'subsample': 0.8671232648084141, 'min_gain_to_split': 468.39251472097123}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:05:29] Stdout logging level is INFO.\n",
      "[13:05:29] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:05:29] Iter 0; Sample 0, NLL-score = 9087.196105507024; \n",
      "[13:05:59] Early stopping at iter 480, best iter 460, best_score 7055.17994270302\n",
      "\u001b[32m[I 2022-12-05 13:06:00,685]\u001b[0m Trial 42 finished with value: 7055.18017578125 and parameters: {'lr': 0.3570930569189841, 'max_depth': 1, 'sketch_outputs': 9, 'lambda_l2': 15.712712992263143, 'colsample': 0.949232260309588, 'subsample': 0.7610593650846125, 'min_gain_to_split': 444.42829252303886}. Best is trial 10 with value: 7036.68359375.\u001b[0m\n",
      "[13:06:00] Stdout logging level is INFO.\n",
      "[13:06:00] GDBT train starts. Max iter 500, early stopping rounds 20\n",
      "[13:06:00] Iter 0; Sample 0, NLL-score = 9148.209767866254; \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Specifies the hyper-parameters and their value range\n",
    "    # The structure is as follows: \"hyper-parameter\": [lower_bound, upper_bound]\n",
    "    # Currently, only the following hyper-parameters can be optimized\n",
    "    \n",
    "hp_dict = {\"lr\": [1e-3, 1],  \n",
    "           \"max_depth\": [1, 4],\n",
    "           \"sketch_outputs\": [1,10],\n",
    "           \"lambda_l2\": [0, 40],     \n",
    "           \"colsample\": [0.2, 1.0],\n",
    "           \"subsample\": [0.2, 1.0],\n",
    "           \"min_gain_to_split\": [0, 500]\n",
    "          }  \n",
    "\n",
    "opt_param = pyboostlss.hyper_opt(dist=distribution,\n",
    "                                 params=hp_dict,\n",
    "                                 dtrain=dtrain,\n",
    "                                 eval_sets=eval_sets,\n",
    "                                 use_hess=True, \n",
    "                                 sketch_method=\"proj\",\n",
    "                                 hp_seed=123,                # Seed for random number generator used in the Bayesian hyper-parameter search.\n",
    "                                 ntrees=500,                 # Number of boosting iterations.\n",
    "                                 es=20,                      # Early stopping rounds\n",
    "                                 n_trials=50,                # The number of trials. If this argument is set to None, there is no limitation on the number of trials.\n",
    "                                 max_minutes=120,            # Time budget in minutes, i.e., stop study after the given number of minutes.\n",
    "                                 silence=False)              # Controls the verbosity of the trail, i.e., user can silence the outputs of the trail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53213379-e7b1-4a4f-8d85-dda5a729f608",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9d38e-fee1-45fd-96cf-4ade74849593",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = opt_param.copy()\n",
    "\n",
    "pyboostlss_model = pyboostlss.train(dist=distribution, \n",
    "                                    dtrain=dtrain,\n",
    "                                    lr=opt_params[\"lr\"], \n",
    "                                    lambda_l2=opt_params[\"lambda_l2\"],\n",
    "                                    max_depth=opt_params[\"max_depth\"],\n",
    "                                    sketch_outputs=opt_params[\"sketch_outputs\"],\n",
    "                                    colsample=opt_params[\"colsample\"],\n",
    "                                    subsample=opt_params[\"subsample\"],\n",
    "                                    min_gain_to_split=opt_params[\"min_gain_to_split\"],\n",
    "                                    ntrees=opt_params[\"opt_rounds\"],\n",
    "                                    use_hess=True,\n",
    "                                    verbose=100,                                \n",
    "                                    sketch_method=\"proj\",\n",
    "                                    seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48228365-d49a-4481-868a-35b7e97535f5",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c126862-1732-4033-a24f-c9e5287fc1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts transformed parameters of the specified distribution. Py-BoostLSS returns the elements of the covariance matrix, instead of the Cholesky factors.\n",
    "predt_params = distribution.predict(model=pyboostlss_model,\n",
    "                                    X_test=x_test,\n",
    "                                    pred_type=\"parameters\")\n",
    "\n",
    "predt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1a565-b8a6-4864-861e-75a81d558528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draws random samples from the predicted distribution\n",
    "torch.manual_seed(123)\n",
    "predt_samples = distribution.predict(model=pyboostlss_model,\n",
    "                                     X_test=x_test,\n",
    "                                     pred_type=\"samples\",   \n",
    "                                     n_samples=1000)\n",
    "\n",
    "predt_samples.shape # Output shape is (n_samples, n_obs, n_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dcd82-94fa-409d-8f62-db9bc7037c98",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79d446-6617-46ce-ae8b-c5209f26abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predt_params[\"x\"] = x_test\n",
    "dist_params = list(predt_params.columns)\n",
    "drop_cols = [resp for resp in list(data_sim.columns) if \"y\" in resp]\n",
    "\n",
    "# Data with actual values\n",
    "plot_df_actual = pd.melt(data_sim.drop(columns=drop_cols, axis=0),\n",
    "                         id_vars=\"x\",\n",
    "                         value_vars=dist_params)\n",
    "plot_df_actual[\"type\"] = \"ACTUAL\"\n",
    "\n",
    "# Data with predicted values\n",
    "plot_df_predt = pd.melt(predt_params,\n",
    "                        id_vars=\"x\",\n",
    "                        value_vars=dist_params)\n",
    "plot_df_predt[\"type\"] = \"FIT\"\n",
    "\n",
    "plot_df = pd.concat([plot_df_actual, plot_df_predt])   \n",
    "\n",
    "plot_df[\"variable\"] = plot_df.variable.str.upper()\n",
    "\n",
    "\n",
    "plot_params = (ggplot(plot_df,\n",
    "                      aes(x=\"x\",\n",
    "                          y=\"value\",\n",
    "                          color=\"type\")) +\n",
    "               geom_line(size=1.1) + \n",
    "               facet_wrap(\"variable\",\n",
    "                          scales=\"free\") + \n",
    "               labs(title=\"Parameters of Trivariate-Gaussian estimated with Py-BoostLSS using Cholesky-Decomposition of Covariance-Matrix\\n\",\n",
    "                    x=\"\",\n",
    "                    y=\"\") + \n",
    "               theme_bw(base_size=15) + \n",
    "               theme(legend_position=\"bottom\",\n",
    "                     legend_title = element_blank(),\n",
    "                     subplots_adjust={\"wspace\": 0.25,\n",
    "                                      \"hspace\": 0.45})\n",
    "              )\n",
    "\n",
    "\n",
    "print(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e1a8c-12a9-4990-a1a8-484664f526c6",
   "metadata": {},
   "source": [
    "Our model approximates well the true shape of the true moments of the trivatiate Gaussian."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
